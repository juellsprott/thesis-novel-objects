{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdmyrPwfHB8b"
      },
      "source": [
        "#### Large RAM is required to load the larger models. Running on GPU can optimize inference speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NWvgu_DnHB8h"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\juel2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import Blip2Processor, Blip2ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk0FfnV4HB8i"
      },
      "source": [
        "#### Load an example image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zKx7P4ftHB8i"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# load sample image\n",
        "raw_image = Image.open(\"data/NOUN-2-600DPI/2007.jpg\").convert(\"RGB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZZzQItwEHB8j"
      },
      "outputs": [],
      "source": [
        "# setup device to use\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgKwm84xHB8k"
      },
      "source": [
        "#### Load pretrained/finetuned BLIP2 captioning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0BK7TxXlHB8k"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin c:\\Users\\juel2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so\n",
            "CUDA SETUP: Loading binary c:\\Users\\juel2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so...\n",
            "argument of type 'WindowsPath' is not iterable\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\juel2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bitsandbytes\\cextension.py:33: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 2&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>processor = Blip2Processor.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">\"Salesforce/blip2-opt-2.7b\"</span>)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 model = Blip2ForConditionalGeneration.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">\"Salesforce/blip2-opt-2.7b\"</span>, load_     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\juel2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_u</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">tils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2740</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2737 │   │   │   │   │   </span>key: device_map[key] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> device_map.keys() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> modu  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2738 │   │   │   │   </span>}                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2739 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"cpu\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> device_map_without_lm_head.values() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"disk\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> device_map_  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2740 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2741 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2742 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">Some modules are dispatched on the CPU or the disk. Make sure yo</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2743 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">the quantized model. If you want to dispatch the model on the CP</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>\n",
              "                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to \n",
              "fit\n",
              "                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n",
              "                        these modules in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-bit, you need to set `<span style=\"color: #808000; text-decoration-color: #808000\">load_in_8bit_fp32_cpu_offload</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>` and pass a \n",
              "custom\n",
              "                        `device_map` to `from_pretrained`. Check\n",
              "                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-</span>\n",
              "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">cpu-and-gpu</span>\n",
              "                        for more details.\n",
              "                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 2>\u001b[0m:\u001b[94m2\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mprocessor = Blip2Processor.from_pretrained(\u001b[33m\"\u001b[0m\u001b[33mSalesforce/blip2-opt-2.7b\u001b[0m\u001b[33m\"\u001b[0m)                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 model = Blip2ForConditionalGeneration.from_pretrained(\u001b[33m\"\u001b[0m\u001b[33mSalesforce/blip2-opt-2.7b\u001b[0m\u001b[33m\"\u001b[0m, load_     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\juel2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_u\u001b[0m \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[33mtils.py\u001b[0m:\u001b[94m2740\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2737 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mkey: device_map[key] \u001b[94mfor\u001b[0m key \u001b[95min\u001b[0m device_map.keys() \u001b[94mif\u001b[0m key \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m modu  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2738 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m}                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2739 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mcpu\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m device_map_without_lm_head.values() \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mdisk\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m device_map_  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2740 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2741 \u001b[0m\u001b[2;90m│   │   │   │   │   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2742 \u001b[0m\u001b[2;33m│   │   │   │   │   │   \u001b[0m\u001b[33mSome modules are dispatched on the CPU or the disk. Make sure yo\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2743 \u001b[0m\u001b[2;33m│   │   │   │   │   │   \u001b[0m\u001b[33mthe quantized model. If you want to dispatch the model on the CP\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mValueError: \u001b[0m\n",
              "                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to \n",
              "fit\n",
              "                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n",
              "                        these modules in \u001b[1;36m32\u001b[0m-bit, you need to set `\u001b[33mload_in_8bit_fp32_cpu_offload\u001b[0m=\u001b[3;92mTrue\u001b[0m` and pass a \n",
              "custom\n",
              "                        `device_map` to `from_pretrained`. Check\n",
              "                        \u001b[4;94mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-\u001b[0m\n",
              "\u001b[4;94mcpu-and-gpu\u001b[0m\n",
              "                        for more details.\n",
              "                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
        "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", load_in_8bit=True, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Peg1vSPEHB8l"
      },
      "source": [
        "#### prepare the image as model input using the associated processors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTna0WvLHB8l"
      },
      "outputs": [],
      "source": [
        "inputs = processor(images=raw_image, return_tensors=\"pt\").to(device, torch.float16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szjNEINiHB8m"
      },
      "source": [
        "#### generate caption using beam search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT5VXAVbHB8m"
      },
      "outputs": [],
      "source": [
        "model.generate({\"image\": image})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmdiTdlcHB8m"
      },
      "source": [
        "#### generate multiple captions using nucleus sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DugSYtG5HB8n"
      },
      "outputs": [],
      "source": [
        "# due to the non-determinstic nature of necleus sampling, you may get different captions.\n",
        "model.generate({\"image\": image}, use_nucleus_sampling=True, num_captions=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnpfGwDFHB8n"
      },
      "source": [
        "#### instructed zero-shot vision-to-language generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_OrT8Q_HB8n"
      },
      "outputs": [],
      "source": [
        "model.generate({\"image\": image, \"prompt\": \"Question: which city is this? Answer:\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m6BgD3DHB8n"
      },
      "outputs": [],
      "source": [
        "model.generate({\n",
        "    \"image\": image,\n",
        "    \"prompt\": \"Question: which city is this? Answer: singapore. Question: why?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11EF7NZvHB8o"
      },
      "outputs": [],
      "source": [
        "context = [\n",
        "    (\"which city is this?\", \"singapore\"),\n",
        "    (\"why?\", \"it has a statue of a merlion\"),\n",
        "]\n",
        "question = \"where is the name merlion coming from?\"\n",
        "template = \"Question: {} Answer: {}.\"\n",
        "\n",
        "prompt = \" \".join([template.format(context[i][0], context[i][1]) for i in range(len(context))]) + \" Question: \" + question + \" Answer:\"\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mud70ZosHB8o"
      },
      "outputs": [],
      "source": [
        "model.generate(\n",
        "    {\n",
        "    \"image\": image,\n",
        "    \"prompt\": prompt\n",
        "    },\n",
        "    use_nucleus_sampling=False,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
